{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7394c18f-cedb-40f3-8e4e-c635c8784e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.1\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff126169-eb84-43b7-aa0f-6d178a818174",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:45: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:45: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\emmad\\AppData\\Local\\Temp\\ipykernel_24508\\1787577988.py:45: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  x=re.findall('\\d\\.\\d+',str(R2[i]))\n",
      "C:\\Users\\emmad\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This python script performs 10-fold cross validation for a dataset for 7 ML methods and outputs the resulting average metrics.\n",
    "The metrics are calculated for each of the 10 folds then the mean taken as the final metrics.\n",
    "INPUTS:\n",
    "MNDO_descriptors_final.csv - a .csv file with the data in. The columns must be named in the same way as below\n",
    "OUTPUTS:\n",
    "MLCV_metrics - a .csv file of the metrics for each ML method for its performance using 10-fold CV.\n",
    "'''\n",
    "#section 1: import modules\n",
    "import sys,os,re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import svm\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn import ensemble\n",
    "from scipy.stats import pearsonr\n",
    "import math\n",
    "from sklearn.model_selection import KFold\n",
    "import statistics\n",
    "\n",
    "##section 2: define inputs and outputs\n",
    "dir = os.getcwd()#get current directory to join to files\n",
    "Dataset=pd.read_csv(os.path.join(dir,\"MNDO_descriptors_final.csv\"))#location of descriptor file\n",
    "output_metrics=os.path.join(dir,\"MLCV_metrics.csv\")#location of output file for MLCV metrics\n",
    "\n",
    "##section 3: define methods\n",
    "#Define statistical measures and R2 conversion\n",
    "#define RMSE\n",
    "def rmse(predictions, targets):\n",
    "\treturn np.sqrt(((predictions - targets) ** 2).mean())\n",
    "#define % within certain range\n",
    "def within_range(list1, list2, range2):\n",
    "\tx=0\n",
    "\tfor i in range(len(list2)):\n",
    "\t\tif (list1[i]-range2)<= list2[i] <= (list1[i]+range2): \n",
    "\t\t\tx+=1\n",
    "\treturn((float(x)/(len(list2)))*100)\n",
    "#define getting R2 method\n",
    "def get_R2(R2):\n",
    "\tR2_2=[]\n",
    "\tfor i in range(len(R2)):\n",
    "\t\tx=re.findall('\\d\\.\\d+',str(R2[i]))\n",
    "\t\tj=float(x[0])\n",
    "\t\tj=j**2\n",
    "\t\tR2_2.append(j)\n",
    "\treturn(R2_2)\n",
    "#define method to get CV results\n",
    "def CV_metrics(Data,folds,C,E,G):\n",
    "\t#initiate lists to add metrics to (one for )\n",
    "\tRMSE=[]\n",
    "\tR2=[]\n",
    "\tN1=[]\n",
    "\tN05=[]\n",
    "\tMLR_RMSE=[]\n",
    "\tMLR_R2=[]\n",
    "\tMLR_N1=[]\n",
    "\tMLR_N05=[]\n",
    "\tANN_RMSE=[]\n",
    "\tANN_R2=[]\n",
    "\tANN_N1=[]\n",
    "\tANN_N05=[]\n",
    "\tSVM_RMSE=[]\n",
    "\tSVM_R2=[]\n",
    "\tSVM_N1=[]\n",
    "\tSVM_N05=[]\n",
    "\tPLS_RMSE=[]\n",
    "\tPLS_R2=[]\n",
    "\tPLS_N1=[]\n",
    "\tPLS_N05=[]\n",
    "\tRF_RMSE=[]\n",
    "\tRF_R2=[]\n",
    "\tRF_N1=[]\n",
    "\tRF_N05=[]\n",
    "\tET_RMSE=[]\n",
    "\tET_R2=[]\n",
    "\tET_N1=[]\n",
    "\tET_N05=[]\n",
    "\tBG_RMSE=[]\n",
    "\tBG_R2=[]\n",
    "\tBG_N1=[]\n",
    "\tBG_N05=[]\n",
    "\t#import Data and randomise\n",
    "\tX = Data\n",
    "\tX = X.sample(frac=1).reset_index(drop=True)\n",
    "\t#define k-fold cross validation and make k splits\n",
    "\tcol_names=X.dtypes.index\n",
    "\tX = np.array(X)\n",
    "\tkf = KFold(n_splits=folds)\n",
    "\t#for every split\n",
    "\tfor train1, test1 in kf.split(X):\n",
    "\t\ttrain=X[train1]\n",
    "\t\ttest=X[test1]\n",
    "\t\ttrain=pd.DataFrame(data=train, columns=col_names)\n",
    "\t\ttest=pd.DataFrame(data=test, columns=col_names)\n",
    "\t\tX_train = train[['MW','Volume','G_sol','DeltaG_sol','sol_dip',\n",
    "\t\t\t\t\t 'Lsolu_Hsolv','Lsolv_Hsolu','SASA','O_charges',\n",
    "\t\t\t\t\t 'C_charges','Most_neg','Most_pos','Het_charges']]\n",
    "\t\ty_train = train['LogS']\n",
    "\t\tX_test = test[['MW','Volume','G_sol','DeltaG_sol','sol_dip',\n",
    "\t\t\t\t\t 'Lsolu_Hsolv','Lsolv_Hsolu','SASA','O_charges',\n",
    "\t\t\t\t\t 'C_charges','Most_neg','Most_pos','Het_charges']]\n",
    "\t\ty_test = test['LogS']\n",
    "\t\ty_test=np.array(y_test)\n",
    "\t\tscaler = preprocessing.StandardScaler().fit(X_train)\n",
    "\t\tX_train = scaler.transform(X_train)\n",
    "\t\tX_test = scaler.transform(X_test)\n",
    "\t\t#run models\n",
    "\t\t#MLR\n",
    "\t\tmlr = LinearRegression()\n",
    "\t\tmlr.fit(X_train, y_train)\n",
    "\t\tmlr2preds = mlr.predict(X_test)\n",
    "\t\t#evaluate model\n",
    "\t\tMLR_R2.append(pearsonr(mlr2preds, y_test))\n",
    "\t\tMLR_RMSE.append(rmse(mlr2preds, y_test))\n",
    "\t\tMLR_N1.append(within_range(y_test,mlr2preds,1))\n",
    "\t\tMLR_N05.append(within_range(y_test,mlr2preds,0.7))\n",
    "\t\t#ANN\n",
    "\t\tmlp = MLPRegressor(hidden_layer_sizes=300,max_iter=800)\n",
    "\t\tfor f in range(100):\n",
    "\t\t\ttry:\n",
    "\t\t\t\tmlp.fit(X_train, y_train)\n",
    "\t\t\t\tmlp2preds = mlp.predict(X_test)\n",
    "\t\t\t\tif np.ptp(mlp2preds) == 0:\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\tbreak\n",
    "\t\t\texcept:\n",
    "\t\t\t\tcontinue\n",
    "\t\t#evaluate model\n",
    "\t\tANN_R2.append(pearsonr(mlp2preds, y_test))\n",
    "\t\tANN_RMSE.append(rmse(mlp2preds, y_test))\n",
    "\t\tANN_N1.append(within_range(y_test,mlp2preds,1))\n",
    "\t\tANN_N05.append(within_range(y_test,mlp2preds,0.7))\n",
    "\t\t#SVM\n",
    "\t\tsvm2 = svm.SVR(C = C, epsilon = E, gamma = G, kernel = 'rbf')\n",
    "\t\tsvm2.fit(X_train, y_train)\n",
    "\t\tsvm2preds = svm2.predict(X_test)\n",
    "\t\t#evaluate model\n",
    "\t\tSVM_R2.append(pearsonr(svm2preds, y_test))\n",
    "\t\tSVM_RMSE.append(rmse(svm2preds, y_test))\n",
    "\t\tSVM_N1.append(within_range(y_test,svm2preds,1))\n",
    "\t\tSVM_N05.append(within_range(y_test,svm2preds,0.7))\n",
    "\t\t#PLS\n",
    "\t\tpls2 = PLSRegression(n_components=9)\n",
    "\t\tpls2.fit(X_train, y_train)\n",
    "\t\tpls2preds = pls2.predict(X_test)\n",
    "\t\t#evaluate model\n",
    "\t\t#convert to float (comes in weird type?)\n",
    "\t\tpls2preds2=[]\n",
    "\t\tfor i in pls2preds:\n",
    "\t\t\tpls2preds2.append(float(i))\n",
    "\t\tPLS_R2.append(pearsonr(pls2preds2, y_test))\n",
    "\t\tPLS_RMSE.append(rmse(pls2preds2, y_test))\n",
    "\t\tPLS_N1.append(within_range(y_test,pls2preds2,1))\n",
    "\t\tPLS_N05.append(within_range(y_test,pls2preds2,0.7))\n",
    "\t\t#RF\n",
    "\t\ttree2 = ensemble.RandomForestRegressor(n_estimators=500,n_jobs=-1)\n",
    "\t\ttree2.fit(X_train, y_train)\n",
    "\t\ttree2preds = tree2.predict(X_test)\n",
    "\t\t#evaluate model\n",
    "\t\tRF_R2.append(pearsonr(tree2preds, y_test))\n",
    "\t\tRF_RMSE.append(rmse(tree2preds, y_test))\n",
    "\t\tRF_N1.append(within_range(y_test,tree2preds,1))\n",
    "\t\tRF_N05.append(within_range(y_test,tree2preds,0.7))\n",
    "\t\t#ExtraTrees\n",
    "\t\ttree3 = ensemble.ExtraTreesRegressor(n_estimators=500,n_jobs=-1)\n",
    "\t\ttree3.fit(X_train, y_train)\n",
    "\t\ttree3preds = tree3.predict(X_test)\n",
    "\t\t#evaluate model\n",
    "\t\tET_R2.append(pearsonr(tree3preds, y_test))\n",
    "\t\tET_RMSE.append(rmse(tree3preds, y_test))\n",
    "\t\tET_N1.append(within_range(y_test,tree3preds,1))\n",
    "\t\tET_N05.append(within_range(y_test,tree3preds,0.7))\n",
    "\t\t#Bagging\n",
    "\t\ttree4 = ensemble.BaggingRegressor(n_estimators=500,n_jobs=-1)\n",
    "\t\ttree4.fit(X_train, y_train)\n",
    "\t\ttree4preds = tree4.predict(X_test)\n",
    "\t\t#evaluate model\n",
    "\t\tBG_R2.append(pearsonr(tree4preds, y_test))\n",
    "\t\tBG_RMSE.append(rmse(tree4preds, y_test))\n",
    "\t\tBG_N1.append(within_range(y_test,tree4preds,1))\n",
    "\t\tBG_N05.append(within_range(y_test,tree4preds,0.7))\n",
    "\t#get R2 from Pearson output\n",
    "\tMLR_R2=get_R2(MLR_R2)\n",
    "\tANN_R2=get_R2(ANN_R2)\n",
    "\tSVM_R2=get_R2(SVM_R2)\n",
    "\tPLS_R2=get_R2(PLS_R2)\n",
    "\tRF_R2=get_R2(RF_R2)\n",
    "\tET_R2=get_R2(ET_R2)\n",
    "\tBG_R2=get_R2(BG_R2)\n",
    "\t#get mean metrics and put together in lists\n",
    "\tR2.append(statistics.mean(MLR_R2))\n",
    "\tRMSE.append(statistics.mean(MLR_RMSE))\n",
    "\tN1.append(statistics.mean(MLR_N1))\n",
    "\tN05.append(statistics.mean(MLR_N05))\n",
    "\t#\n",
    "\tR2.append(statistics.mean(ANN_R2))\n",
    "\tRMSE.append(statistics.mean(ANN_RMSE))\n",
    "\tN1.append(statistics.mean(ANN_N1))\n",
    "\tN05.append(statistics.mean(ANN_N05))\n",
    "\t#\n",
    "\tR2.append(statistics.mean(SVM_R2))\n",
    "\tRMSE.append(statistics.mean(SVM_RMSE))\n",
    "\tN1.append(statistics.mean(SVM_N1))\n",
    "\tN05.append(statistics.mean(SVM_N05))\n",
    "\t#\n",
    "\tR2.append(statistics.mean(PLS_R2))\n",
    "\tRMSE.append(statistics.mean(PLS_RMSE))\n",
    "\tN1.append(statistics.mean(PLS_N1))\n",
    "\tN05.append(statistics.mean(PLS_N05))\n",
    "\t#\n",
    "\tR2.append(statistics.mean(RF_R2))\n",
    "\tRMSE.append(statistics.mean(RF_RMSE))\n",
    "\tN1.append(statistics.mean(RF_N1))\n",
    "\tN05.append(statistics.mean(RF_N05))\n",
    "\t#\n",
    "\tR2.append(statistics.mean(ET_R2))\n",
    "\tRMSE.append(statistics.mean(ET_RMSE))\n",
    "\tN1.append(statistics.mean(ET_N1))\n",
    "\tN05.append(statistics.mean(ET_N05))\n",
    "\t#\n",
    "\tR2.append(statistics.mean(BG_R2))\n",
    "\tRMSE.append(statistics.mean(BG_RMSE))\n",
    "\tN1.append(statistics.mean(BG_N1))\n",
    "\tN05.append(statistics.mean(BG_N05))\n",
    "\t#\n",
    "\t#create dataframe of metrics\n",
    "\tModels=[\"MLR\",\"ANN\",\"SVM\",\"PLS\",\"RF\",\"ExtraTrees\",\"Bagging\"]\n",
    "\tMetrics=list(zip(Models,R2,RMSE,N1,N05))\n",
    "\tMetrics_df=pd.DataFrame(data=Metrics, columns=['Model','R2','RMSE','% within 1','% within 0.7'])\n",
    "\treturn(Metrics_df)\n",
    "##method to put it all together\n",
    "def get_CV_metrics(Dataset,output_metrics):\n",
    "\t##get metrics\n",
    "\tCV_metrics2=CV_metrics(Dataset,10,4,0.01,0.03)##10-folds and SVM parameters\n",
    "\t##save to file\n",
    "\tCV_metrics2.to_csv(output_metrics,index=False)\n",
    "\n",
    "##section 4: run CV method and get metrics\n",
    "get_CV_metrics(Dataset,output_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4c07c5-707b-4027-889b-8f09d2b6dbcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
